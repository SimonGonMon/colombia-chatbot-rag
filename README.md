# Colombia Chatbot RAG

Este proyecto implementa un chatbot especializado en responder preguntas sobre Colombia, utilizando informaci칩n extra칤da de Wikipedia. El sistema se basa en una arquitectura RAG (Retrieval-Augmented Generation) para proporcionar respuestas precisas y contextualizadas.

**Tecnolog칤as Principales:**
*   **Backend:** FastAPI
*   **Frontend:** Streamlit
*   **Orquestaci칩n LLM:** LangChain
*   **Modelos de Lenguaje:** OpenAI gpt-4o (principal) y gpt-4o-mini (apoyo)
*   **Embeddings:** OpenAI text-embedding-3-small
*   **Base de Datos Vectorial:** Pinecone
*   **Base de Datos Conversacional:** PostgreSQL (v칤a Alembic para migraciones)
*   **Contenerizaci칩n:** Docker

## Capacidades Avanzadas del Chatbot

Este chatbot va m치s all치 de una simple respuesta, incorporando l칩gicas complejas para ofrecer una experiencia conversacional superior:

*   **Especializaci칩n por Tipo de Pregunta:** El chatbot adapta su "persona" (historiador, ge칩grafo, antrop칩logo cultural) seg칰n la intenci칩n de la pregunta, proporcionando respuestas m치s precisas y enfocadas.
*   **Respuestas Estructuradas:** Las respuestas se presentan en un formato claro y consistente, incluyendo una respuesta directa, detalles clave y contexto adicional, facilitando la comprensi칩n.
*   **Validaci칩n de Relevancia:** Solo responde preguntas relacionadas con Colombia. Si la pregunta est치 fuera de su dominio, lo indica amablemente.
*   **Complejidad de Respuesta Gradual:** Ajusta el nivel de detalle de la respuesta (breve, balanceada o detallada) seg칰n las palabras clave en la pregunta del usuario.
*   **Citas Inteligentes:** Proporciona la secci칩n espec칤fica de Wikipedia de donde se extrajo la informaci칩n, aumentando la transparencia y la confianza en las respuestas.
*   **Conversaciones con Estado (Stateful):** Gracias a su integraci칩n con una base de datos, el chatbot puede recordar el contexto de conversaciones pasadas, permitiendo di치logos fluidos y coherentes a lo largo del tiempo.

## C칩mo Ejecutar el Proyecto

Puedes ejecutar la aplicaci칩n completa usando Docker Compose o levantar cada servicio (API y Streamlit) de forma local.

### Nota sobre la Configuraci칩n Inicial

**Si se te han proporcionado las variables de entorno para este proyecto (por ejemplo, como parte de una prueba t칠cnica 游뱕), la base de datos ya est치 configurada y puedes omitir el paso de la migraci칩n con Alembic.**

Si est치s configurando el proyecto desde cero por tu cuenta, necesitar치s inicializar la base de datos:
1.  Crea tu archivo `.env` a partir del `.env.example` y rellena tus propias credenciales.
2.  Ejecuta las migraciones de la base de datos con Alembic:
    ```bash
    alembic upgrade head
    ```

### Usando Docker Compose (Recomendado)

Este es el m칠todo m치s sencillo para poner en marcha todo el sistema.

1.  Aseg칰rate de tener Docker y Docker Compose instalados.
2.  En la ra칤z del proyecto, ejecuta el siguiente comando:
    ```bash
    docker-compose up --build
    ```
3.  Una vez que los contenedores est칠n en funcionamiento:
    *   Accede a la interfaz del chatbot en: **http://localhost:8501**
    *   La documentaci칩n interactiva de la API (Scalar) estar치 disponible en: **http://localhost:8000**

### Ejecuci칩n Local

Si prefieres no usar Docker, puedes ejecutar la API y la aplicaci칩n de Streamlit por separado.

#### Prerrequisitos y Configuraci칩n

1.  **Instalar uv (Recomendado)**: La forma m치s r치pida de configurar el entorno es con `uv`. Se recomienda instalarlo en tu entorno global de Python.
    ```bash
    pip install uv
    ```
    Luego, desde la ra칤z del proyecto, ejecuta:
    ```bash
    uv sync
    ```
    Este comando leer치 el `pyproject.toml`, usar치 el `uv.lock` para instalar las versiones exactas de las dependencias y crear치 un entorno virtual en `.venv` si no existe.

2.  **Alternativa (pip + venv)**: Si prefieres no usar `uv`, puedes seguir el m칠todo tradicional:
    ```bash
    # Crear y activar un entorno virtual
    python -m venv .venv
    source .venv/bin/activate
    # Instalar dependencias
    pip install -r requirements.txt
    ```

3.  **Activar el Entorno Virtual**: Antes de continuar, aseg칰rate de que el entorno est칠 activado:
    ```bash
    source .venv/bin/activate
    ```

#### 1. Iniciar la API (Backend)

Con el entorno virtual activado, inicia el servidor de la API en modo desarrollo:
```bash
fastapi dev src/api/main.py
```
La API estar치 escuchando en `http://localhost:8000`.

#### 2. Iniciar Streamlit (Frontend)

En una **nueva terminal**, activa el mismo entorno virtual:
```bash
source .venv/bin/activate
```
Luego, ejecuta la aplicaci칩n de Streamlit:
```bash
streamlit run streamlit_app/app.py
```
La interfaz de usuario estar치 disponible en `http://localhost:8501`.


## Arquitectura del Proyecto

### Flujo RAG (Retrieval-Augmented Generation)

El n칰cleo del chatbot es un sistema RAG orquestado por **LangChain**. Los archivos clave se encuentran en `src/rag/`:

*   `data_extractor.py`: Extrae el contenido de texto desde la p치gina de Wikipedia sobre Colombia.
*   `text_processor.py`: Limpia y divide el texto en fragmentos (`chunks`).
*   `embeddings.py`: Utiliza **OpenAI text-embedding-3-small** para convertir cada fragmento en un vector.
*   `vector_store.py`: Almacena y gestiona los vectores en una base de datos vectorial de **Pinecone**, permitiendo b칰squedas de similitud eficientes.

### API (FastAPI)

La API expone la l칩gica del chatbot y gestiona las conversaciones.

#### Endpoint Principal

*   `POST /api/v1/chat/`
    Este endpoint es el coraz칩n de la interacci칩n. Recibe una pregunta y, opcionalmente, un `conversation_id`. Si no se proporciona un ID, se crea una nueva conversaci칩n autom치ticamente.
    *   **Modelo Principal:** **OpenAI gpt-4o** genera la respuesta final bas치ndose en el contexto recuperado de Pinecone.
    *   **Modelo de Apoyo:** **OpenAI gpt-4o-mini** reformula la pregunta del usuario para incluir el contexto de mensajes anteriores, mejorando la coherencia.

#### Endpoints de Conversaci칩n

*   `POST /api/v1/conversations/`
*   `GET /api/v1/conversations/`
*   `GET /api/v1/conversations/{conversation_id}`

Estos endpoints hacen que el chatbot sea *stateful*, permitiendo crear, listar y recuperar conversaciones. La informaci칩n se almacena en una base de datos PostgreSQL.

### Interfaz de Usuario (Streamlit)

La carpeta `streamlit_app/` contiene la interfaz web interactiva que act칰a como cliente de la API, permitiendo a los usuarios chatear y gestionar sus conversaciones.

### Docker

El proyecto est치 completamente dockerizado para un despliegue sencillo y portable.
*   `Dockerfile`: Define la imagen para la API de FastAPI.
*   `Dockerfile.streamlit`: Define la imagen para la interfaz de Streamlit.
*   `docker-compose.yml`: Orquesta la ejecuci칩n de ambos servicios, sus redes y configuraciones.
